{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation of dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\anaconda\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\anaconda\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: sklearn in c:\\anaconda\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: nltk in c:\\anaconda\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\anaconda\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\anaconda\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\anaconda\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\anaconda\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: packaging in c:\\anaconda\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\anaconda\\lib\\site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\anaconda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\anaconda\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\anaconda\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\lib\\site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: joblib in c:\\anaconda\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\anaconda\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\anaconda\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn->sklearn) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "# Data preprocessing################################\n",
    "# Remove useless words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Aggressive conversion of words to base form\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "# Import packages that help us to create document-term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# Data preprocessing################################\n",
    "\n",
    "# Data visualization################################\n",
    "\n",
    "# For creating graphs\n",
    "from matplotlib import pyplot as plt\n",
    "# Data visualization################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Ti, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# Setting the dtype policy to utilize mixed precision\n",
    "# This will use the tensor cores of the GPU\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools to split data and evaluate model performance\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, fbeta_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Import ML algos\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_colab\\\\train.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join('train_colab', 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('train_colab', 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'china teammate so toxic'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3]['TextComment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Toxic              1\n",
       "SevereToxicity     0\n",
       "ObsceneLanguage    0\n",
       "Insult             1\n",
       "Name: 3, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[2:]].iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset overview\n",
    "The overview will conclude a discussion with the dataset using exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128606"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show rows of the dataset\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.889655\n",
       "1    0.110345\n",
       "Name: Toxic, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check percentage of comments that are toxic compared to normal comments\n",
    "df.Toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This states that approximately 11.03% of the dataset is toxic compared to normal comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Toxic              14191\n",
       "SevereToxicity      1597\n",
       "ObsceneLanguage     7889\n",
       "Insult              7499\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new subset of the data by only taking the 2nd column onwards (comments and categories)\n",
    "df_count=df.iloc[:,2:].sum()\n",
    "\n",
    "# Print dataset summary\n",
    "df_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Toxic', 'SevereToxicity', 'ObsceneLanguage', 'Insult'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_count.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\tf_2.9\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a chart with the following size\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "# Plot a bar chart using the index (category values) and the count of each category. \n",
    "# To make the bars more translucent, modify alpha value\n",
    "ax = sns.barplot(df_count.index, df_count.values, alpha=1)\n",
    "\n",
    "plt.title(\"Comments per class\\n\", fontsize=20)\n",
    "plt.ylabel('Occurrences', fontsize=12)\n",
    "plt.xlabel('Toxicity class', fontsize=12)\n",
    "\n",
    "# Adding the text labels for each bar\n",
    "rects = ax.patches\n",
    "labels = df_count.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 10, label, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.0344774 ,  1.24177721,  6.13423946,  5.83098767])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rowdata = len(df)\n",
    "\n",
    "pctdata = df_count.values / rowdata * 100\n",
    "pctdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### This concludes that the percentage of toxicity classes are:\n",
    "    - Toxicity: 11.03%\n",
    "    - Severe Toxicity: 1.24%\n",
    "    - Obscene Language: 6.13%\n",
    "    - Insult: 5.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Maltesers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Maltesers\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "# Re-download stopwords for backup\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Setup stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove numbers, capital letters, punctuation, '\\n'\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Remove all random numbers with attached letters\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "\n",
    "# '[%s]' % re.escape(string.punctuation),' ' - replace punctuation with white space\n",
    "# .lower() - Convert all strings to lowercase \n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "# Remove all '\\n' in the string and replace it with a space\n",
    "filter_line = lambda x: re.sub(\"\\n\", \" \", x)\n",
    "\n",
    "# Remove all Non-ASCII characters \n",
    "filter_non_ascii = lambda x: re.sub(r'[^\\x00-\\x7f]',r' ', x)\n",
    "\n",
    "# Apply all the lambda functions wrote previously through .map on the comments column\n",
    "df['TextComment'] = df['TextComment'].map(alphanumeric).map(punc_lower).map(filter_line).map(filter_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through your rows\n",
    "for sent in df['TextComment']:\n",
    "\n",
    "    # tokenize\n",
    "    tokenized_sent = nltk.word_tokenize(sent)\n",
    "\n",
    "    # remove stops\n",
    "    tokenized_sent_no_stops = [\n",
    "        tok for tok in tokenized_sent \n",
    "        if tok not in stop_words\n",
    "    ]\n",
    "\n",
    "    # untokenize \n",
    "    untokenized_sent = TreebankWordDetokenizer().detokenize(\n",
    "        tokenized_sent_no_stops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'your new user tags   hey man   i just noticed that you put a little tag on your user page saying that vandals dont like you  that is most certainly not the case    well  at least not as far as i m concerned  the only reason that i keep screwing around with you is because you re the only admin that s banned me who has a memorable  easy to spell name  honestly  it s nothing personal   just trying to put a smile on your face '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View comment\n",
    "df['TextComment'][50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df['TextComment']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'TextComment', 'Toxic', 'SevereToxicity', 'ObsceneLanguage',\n",
       "       'Insult'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TextComment</th>\n",
       "      <th>Toxic</th>\n",
       "      <th>SevereToxicity</th>\n",
       "      <th>ObsceneLanguage</th>\n",
       "      <th>Insult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go back to your country smelly arab</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>russian why u mad bitch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man  i m really not trying to edit war  it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>china teammate so toxic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you  sir  are my hero  any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128601</th>\n",
       "      <td>baiter fucking idiot</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128602</th>\n",
       "      <td>you should be ashamed of yourself  that is a h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128603</th>\n",
       "      <td>fking noob</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128604</th>\n",
       "      <td>and it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128605</th>\n",
       "      <td>and     i really don t think you understand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128606 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TextComment  Toxic  \\\n",
       "0                     go back to your country smelly arab      0   \n",
       "1                                 russian why u mad bitch      0   \n",
       "2       hey man  i m really not trying to edit war  it...      0   \n",
       "3                                 china teammate so toxic      1   \n",
       "4       you  sir  are my hero  any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "128601                               baiter fucking idiot      0   \n",
       "128602  you should be ashamed of yourself  that is a h...      0   \n",
       "128603                                         fking noob      0   \n",
       "128604  and it looks like it was actually you who put ...      0   \n",
       "128605    and     i really don t think you understand ...      0   \n",
       "\n",
       "        SevereToxicity  ObsceneLanguage  Insult  \n",
       "0                    1                0       1  \n",
       "1                    1                1       1  \n",
       "2                    0                0       0  \n",
       "3                    0                0       1  \n",
       "4                    0                0       0  \n",
       "...                ...              ...     ...  \n",
       "128601               1                1       1  \n",
       "128602               0                0       1  \n",
       "128603               1                1       1  \n",
       "128604               0                0       0  \n",
       "128605               0                0       0  \n",
       "\n",
       "[128606 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_WORDS = 250000 # number of words in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=MAX_WORDS,\n",
    "                               output_sequence_length=1800,\n",
    "                               output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer=text.Tokenizer(MAX_WORDS, oov_token=oov_tok)\n",
    "#tokenizer.fit_on_texts(list(x))\n",
    "#tokenized=tokenizer.texts_to_sequences(x)\n",
    "#X_train=sequence.pad_sequences(tokenized,maxlen=max_text_len, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorized_text = vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([376, 698], dtype=int64)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer('Hello, test')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128606, 1800), dtype=int64, numpy=\n",
       "array([[  112,   155,     3, ...,     0,     0,     0],\n",
       "       [ 1117,    76,   188, ...,     0,     0,     0],\n",
       "       [  322,   367,     4, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [25107,  6365,     0, ...,     0,     0,     0],\n",
       "       [    6,    11,   525, ...,     0,     0,     0],\n",
       "       [    6,     4,   123, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128606"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Particularly helpful if you have a large dataset\n",
    "# This is a data pipeline\n",
    "# MCShBP - map, cache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8) # helps bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_X, batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1800)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.data.ops.dataset_ops.DatasetV2.list_files(file_pattern, shuffle=None, seed=None, name=None)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.data.Dataset.list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*0.7))\n",
    "val = dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2))\n",
    "test = dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_generator = train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 91346,   1219,    841, ...,      0,      0,      0],\n",
       "        [     4,     57,     22, ...,      0,      0,      0],\n",
       "        [    63,   1441,      6, ...,      0,      0,      0],\n",
       "        ...,\n",
       "        [     2,    585,  29950, ...,      0,      0,      0],\n",
       "        [   493,  10981, 113494, ...,      0,      0,      0],\n",
       "        [     4,    187,      2, ...,      0,      0,      0]], dtype=int64),\n",
       " array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Bidirectional??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#LSTM??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Dense??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          8000032   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 32)          0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,037,668\n",
      "Trainable params: 8,037,668\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Create the embedding layer\n",
    "model.add(Embedding(MAX_WORDS+1, 32))\n",
    "\n",
    "# Dropout layer\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Bidirectional LSTM Layer\n",
    "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
    "\n",
    "# Feature extractor Fully connected layers\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# Dropout layer\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Final layer \n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use Adam\n",
    "# Adam(learning rate)\n",
    "optimizers = tf.keras.optimizers.Adam(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='BinaryCrossentropy', optimizer=optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training the model and displaying chart containing Loss and Validation Loss\n",
    "**_val_loss_** is the value of cost function for your cross-validation data. <br>\n",
    "**_loss_** is the value of cost function for your training data.\n",
    "\n",
    "On validation data, neurons using drop out do not drop random neurons. The reason is that during training we use drop out in order to add some noise for avoiding over-fitting. During calculating cross-validation, we are in the recall phase and not in the training phase. We use all the capabilities of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train,batch_X,y_train,batch_y=train_test_split(X_train,y,test_size=0.15,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5626/5626 [==============================] - 451s 79ms/step - loss: 0.1573 - val_loss: 0.0963\n",
      "Epoch 2/20\n",
      "5626/5626 [==============================] - 452s 80ms/step - loss: 0.0939 - val_loss: 0.0812\n",
      "Epoch 3/20\n",
      "5626/5626 [==============================] - 449s 80ms/step - loss: 0.0827 - val_loss: 0.0713\n",
      "Epoch 4/20\n",
      "5626/5626 [==============================] - 445s 79ms/step - loss: 0.0766 - val_loss: 0.0690\n",
      "Epoch 5/20\n",
      "5626/5626 [==============================] - 445s 79ms/step - loss: 0.0708 - val_loss: 0.0648\n",
      "Epoch 6/20\n",
      "5626/5626 [==============================] - 445s 79ms/step - loss: 0.0674 - val_loss: 0.0593\n",
      "Epoch 7/20\n",
      "5626/5626 [==============================] - 447s 79ms/step - loss: 0.0645 - val_loss: 0.0573\n",
      "Epoch 8/20\n",
      "5626/5626 [==============================] - 448s 80ms/step - loss: 0.0626 - val_loss: 0.0554\n",
      "Epoch 9/20\n",
      "5626/5626 [==============================] - 447s 80ms/step - loss: 0.0607 - val_loss: 0.0535\n",
      "Epoch 10/20\n",
      "5626/5626 [==============================] - 453s 81ms/step - loss: 0.0600 - val_loss: 0.0542\n",
      "Epoch 11/20\n",
      "5626/5626 [==============================] - 455s 81ms/step - loss: 0.0585 - val_loss: 0.0521\n",
      "Epoch 12/20\n",
      "5626/5626 [==============================] - 445s 79ms/step - loss: 0.0575 - val_loss: 0.0517\n",
      "Epoch 13/20\n",
      "5626/5626 [==============================] - 453s 81ms/step - loss: 0.0568 - val_loss: 0.0502\n",
      "Epoch 14/20\n",
      "5626/5626 [==============================] - 448s 80ms/step - loss: 0.0559 - val_loss: 0.0513\n",
      "Epoch 15/20\n",
      "5626/5626 [==============================] - 445s 79ms/step - loss: 0.0548 - val_loss: 0.0513\n",
      "Epoch 16/20\n",
      "5626/5626 [==============================] - 449s 80ms/step - loss: 0.0540 - val_loss: 0.0475\n",
      "Epoch 17/20\n",
      "5626/5626 [==============================] - 446s 79ms/step - loss: 0.0536 - val_loss: 0.0486\n",
      "Epoch 18/20\n",
      "5626/5626 [==============================] - 447s 79ms/step - loss: 0.0530 - val_loss: 0.0507\n",
      "Epoch 19/20\n",
      "5626/5626 [==============================] - 448s 80ms/step - loss: 0.0521 - val_loss: 0.0470\n",
      "Epoch 20/20\n",
      "5626/5626 [==============================] - 451s 80ms/step - loss: 0.0514 - val_loss: 0.0458\n"
     ]
    }
   ],
   "source": [
    "# Train the dataset\n",
    "# Epoch = how many passes for dataset\n",
    "batch_size=64\n",
    "archive=model.fit(train, epochs=20, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "pd.DataFrame(archive.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model after training, load model function(H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data after training Epoch1_3:52pm 07/August/2022\n",
    "model.save('epoch20_DP4_dense-64-128-64_DP4_trainer.h5')\n",
    "# Load model data\n",
    "model = tf.keras.models.load_model('epoch20_DP4_dense-64-128-64_DP4_trainer.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = vectorizer('russian idiot noob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Toxic', 'SevereToxicity', 'ObsceneLanguage', 'Insult'], dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 616ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.959 , 0.1757, 0.877 , 0.6567]], dtype=float16)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(input_text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 1, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(batch_X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.959 , 0.1757, 0.877 , 0.6567]], dtype=float16)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_pre = Precision()\n",
    "model_rec = Recall()\n",
    "model_acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    \n",
    "    # Unpack the batch \n",
    "    X_true, y_true = batch\n",
    "    \n",
    "    # Make a prediction \n",
    "    yhat = model.predict(X_true)\n",
    "    \n",
    "    # Flatten the predictions\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "    \n",
    "    model_pre.update_state(y_true, yhat)\n",
    "    model_rec.update_state(y_true, yhat)\n",
    "    model_acc.update_state(y_true, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8611869215965271,Recall:0.813466489315033, Accuracy:0.48692402243614197\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {model_pre.result().numpy()},Recall:{model_rec.result().numpy()}, Accuracy:{model_acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test and Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\anaconda\\lib\\site-packages (3.1.3)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (2.11.3)\n",
      "Requirement already satisfied: analytics-python in c:\\anaconda\\lib\\site-packages (from gradio) (1.4.0)\n",
      "Requirement already satisfied: paramiko in c:\\anaconda\\lib\\site-packages (from gradio) (2.8.1)\n",
      "Requirement already satisfied: python-multipart in c:\\anaconda\\lib\\site-packages (from gradio) (0.0.5)\n",
      "Requirement already satisfied: pandas in c:\\anaconda\\lib\\site-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from gradio) (1.21.5)\n",
      "Requirement already satisfied: ffmpy in c:\\anaconda\\lib\\site-packages (from gradio) (0.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\anaconda\\lib\\site-packages (from gradio) (3.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\anaconda\\lib\\site-packages (from gradio) (3.5.1)\n",
      "Requirement already satisfied: httpx in c:\\anaconda\\lib\\site-packages (from gradio) (0.23.0)\n",
      "Requirement already satisfied: pydub in c:\\anaconda\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from gradio) (2.27.1)\n",
      "Requirement already satisfied: fastapi in c:\\anaconda\\lib\\site-packages (from gradio) (0.79.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify,plugins] in c:\\anaconda\\lib\\site-packages (from gradio) (2.1.0)\n",
      "Requirement already satisfied: h11<0.13,>=0.11 in c:\\anaconda\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: pycryptodome in c:\\anaconda\\lib\\site-packages (from gradio) (3.15.0)\n",
      "Requirement already satisfied: pydantic in c:\\anaconda\\lib\\site-packages (from gradio) (1.9.1)\n",
      "Requirement already satisfied: orjson in c:\\anaconda\\lib\\site-packages (from gradio) (3.7.11)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda\\lib\\site-packages (from gradio) (2022.2.0)\n",
      "Requirement already satisfied: pillow in c:\\anaconda\\lib\\site-packages (from gradio) (9.0.1)\n",
      "Requirement already satisfied: uvicorn in c:\\anaconda\\lib\\site-packages (from gradio) (0.18.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda\\lib\\site-packages (from jinja2) (2.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda\\lib\\site-packages (from aiohttp->gradio) (1.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda\\lib\\site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\anaconda\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda\\lib\\site-packages (from aiohttp->gradio) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\anaconda\\lib\\site-packages (from aiohttp->gradio) (4.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda\\lib\\site-packages (from aiohttp->gradio) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda\\lib\\site-packages (from aiohttp->gradio) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\anaconda\\lib\\site-packages (from async-timeout<5.0,>=4.0.0a3->aiohttp->gradio) (4.1.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\anaconda\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (3.3)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\anaconda\\lib\\site-packages (from analytics-python->gradio) (1.6)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\anaconda\\lib\\site-packages (from analytics-python->gradio) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from analytics-python->gradio) (1.16.0)\n",
      "Requirement already satisfied: backoff==1.10.0 in c:\\anaconda\\lib\\site-packages (from analytics-python->gradio) (1.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->gradio) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->gradio) (2021.10.8)\n",
      "Requirement already satisfied: starlette==0.19.1 in c:\\anaconda\\lib\\site-packages (from fastapi->gradio) (0.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\anaconda\\lib\\site-packages (from starlette==0.19.1->fastapi->gradio) (3.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\anaconda\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi->gradio) (1.2.0)\n",
      "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in c:\\anaconda\\lib\\site-packages (from httpx->gradio) (1.5.0)\n",
      "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in c:\\anaconda\\lib\\site-packages (from httpx->gradio) (0.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\anaconda\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.1)\n",
      "Requirement already satisfied: mdit-py-plugins in c:\\anaconda\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.0)\n",
      "Requirement already satisfied: linkify-it-py~=1.0 in c:\\anaconda\\lib\\site-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
      "Requirement already satisfied: uc-micro-py in c:\\anaconda\\lib\\site-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->gradio) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda\\lib\\site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->gradio) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from matplotlib->gradio) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda\\lib\\site-packages (from matplotlib->gradio) (1.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas->gradio) (2021.3)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\anaconda\\lib\\site-packages (from paramiko->gradio) (3.4.8)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in c:\\anaconda\\lib\\site-packages (from paramiko->gradio) (3.2.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in c:\\anaconda\\lib\\site-packages (from paramiko->gradio) (1.4.0)\n",
      "Requirement already satisfied: cffi>=1.1 in c:\\anaconda\\lib\\site-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda\\lib\\site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n",
      "Requirement already satisfied: click>=7.0 in c:\\anaconda\\lib\\site-packages (from uvicorn->gradio) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from click>=7.0->uvicorn->gradio) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_str = vectorizer('fucking noob china man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(np.expand_dims(input_str,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.974 , 0.303 , 0.9536, 0.739 ]], dtype=float16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_comment(Chat):\n",
    "    vectorized_comment = vectorizer([Chat])\n",
    "    results = model.predict(vectorized_comment)\n",
    "    \n",
    "    text = ''\n",
    "    for idx, col in enumerate(df.columns[2:]):\n",
    "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\tf_2.9\\lib\\site-packages\\gradio\\inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Anaconda\\envs\\tf_2.9\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Anaconda\\envs\\tf_2.9\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Anaconda\\envs\\tf_2.9\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    }
   ],
   "source": [
    "interface = gr.Interface(fn=score_comment, \n",
    "                         inputs=gr.inputs.Textbox(lines=2, placeholder='Type to evaluate'),\n",
    "                        outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x1b7d46c8fd0>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n",
      "1/1 [==============================] - 0s 238ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n"
     ]
    }
   ],
   "source": [
    "interface.launch(share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
